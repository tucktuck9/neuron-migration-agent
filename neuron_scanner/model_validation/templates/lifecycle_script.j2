{# Lifecycle Script for SageMaker Notebook Instance Neuron Compilation #}
{# ===================================================================== #}
{#
ARCHITECTURE:
    This script runs on SageMaker Notebook Instance startup via lifecycle configuration.
    It downloads the model, runs Neuron compilation in a Docker container, and uploads results.

VARIABLES:
    model_s3_uri: S3 URI to the model.tar.gz file
    output_s3_uri: S3 URI prefix for output (result.json, compiled_model.pt)
    script_s3_uri: S3 URI to the compile_script.py
    input_shape_str: Comma-separated input shape (e.g., "1,512") or empty for auto-detect
    region: AWS region
    container_image: Full Neuron DLC image URI from public ECR
    neuron_sdk_version: Neuron SDK version (e.g., "2.27.1") extracted from container_image
#}
#!/bin/bash
set -e

# =============================================================================
# Environment Variables
# =============================================================================
export MODEL_S3_URI="{{ model_s3_uri }}"
export OUTPUT_S3_URI="{{ output_s3_uri }}"
export SCRIPT_S3_URI="{{ script_s3_uri }}"
export INPUT_SHAPE="{{ input_shape_str }}"

# =============================================================================
# Logging
# =============================================================================
echo "Starting Neuron compilation lifecycle script..."
echo "MODEL_S3_URI: $MODEL_S3_URI"
echo "OUTPUT_S3_URI: $OUTPUT_S3_URI"

# =============================================================================
# Setup Working Directories
# =============================================================================
mkdir -p /tmp/neuron-compile/model
mkdir -p /tmp/neuron-compile/output
chmod -R 777 /tmp/neuron-compile  # Ensure Docker has write access

# =============================================================================
# Download Model and Compile Script
# =============================================================================
aws s3 cp "$MODEL_S3_URI" /tmp/neuron-compile/model.tar.gz

cd /tmp/neuron-compile/model
tar -xzf ../model.tar.gz

aws s3 cp "$SCRIPT_S3_URI" /tmp/neuron-compile/compile_script.py

# =============================================================================
# Configure Docker to Use EBS Volume (for large training containers)
# =============================================================================
echo "Configuring Docker to use EBS volume..."

# Stop Docker daemon
sudo systemctl stop docker

# Create Docker directory on EBS volume (50-100 GB available)
sudo mkdir -p /home/ec2-user/SageMaker/docker

# Backup old Docker data if it exists
if [ -d /var/lib/docker ]; then
    sudo mv /var/lib/docker /var/lib/docker.backup 2>/dev/null || true
fi

# Configure Docker daemon to use EBS volume
sudo tee /etc/docker/daemon.json > /dev/null <<EOF
{
  "data-root": "/home/ec2-user/SageMaker/docker"
}
EOF

# Start Docker with new configuration
sudo systemctl start docker
sudo systemctl status docker --no-pager || true

echo "‚úÖ Docker configured to use EBS volume"
echo "Available space on EBS:"
df -h /home/ec2-user/SageMaker

# =============================================================================
# Run Compilation in Docker (AWS Neuron DLC)
# =============================================================================
echo "Pulling Neuron DLC image from public ECR..."
echo "Image: {{ container_image }}"
docker pull {{ container_image }}

echo "Running compilation inside Docker..."
# We map /tmp/neuron-compile (host) to /app (container)
# We install transformers/safetensors just in case the DLC version is old
docker run --rm \
    -v /tmp/neuron-compile:/app \
    -e INPUT_SHAPE="$INPUT_SHAPE" \
    {{ container_image }} \
    /bin/bash -c "pip install --upgrade transformers safetensors && cd /app && python3 compile_script.py --input-dir /app/model --output-dir /app/output" || {
    echo "ERROR: Docker compilation failed"
    # Create an error result so the validator knows it failed
    echo '{"status": "ERROR", "error": "Docker compilation failed. Check CloudWatch logs for details."}' > /tmp/neuron-compile/output/result.json
    aws s3 cp /tmp/neuron-compile/output/result.json "$OUTPUT_S3_URI/result.json"
    exit 1
}

echo "‚úÖ Docker compilation complete"

# =============================================================================
# Validate Model Load in Docker (Same Environment)
# =============================================================================
echo ""
echo "üß™ Testing model load in Docker container..."

# Discover Neuron devices on the host
echo "Discovering Neuron devices..."
NEURON_DEVICES=""
for dev in /dev/neuron*; do
    if [ -e "$dev" ]; then
        NEURON_DEVICES="$NEURON_DEVICES --device=$dev"
        echo "  Found: $dev"
    fi
done

if [ -z "$NEURON_DEVICES" ]; then
    echo "‚ö†Ô∏è  Warning: No Neuron devices found. Model load test may fail."
    echo "  This is expected if not running on an Inferentia/Trainium instance."
fi

docker run --rm \
    $NEURON_DEVICES \
    -v /tmp/neuron-compile:/app \
    {{ container_image }} \
    /bin/bash -c "
python3 << 'LOADTEST'
import torch
import torch_neuronx
import json
import sys

print(f'Using torch-neuronx: {torch_neuronx.__version__}')

try:
    model_path = '/app/output/compiled_model.pt'
    print(f'Loading model from: {model_path}')
    
    compiled_model = torch.jit.load(model_path)
    
    result = {
        'status': 'COMPATIBLE',
        'message': 'Model compiled and loaded successfully',
        'torch_neuronx_version': torch_neuronx.__version__,
        'pytorch_version': torch.__version__,
        'environment': 'Docker Neuron DLC'
    }
    print(f\"‚úÖ {result['message']}\")
    
except Exception as e:
    result = {
        'status': 'ERROR',
        'error': str(e),
        'torch_neuronx_version': torch_neuronx.__version__,
        'pytorch_version': torch.__version__
    }
    print(f'‚ùå Load test failed: {e}')
    sys.exit(1)

# Save result
with open('/app/output/result.json', 'w') as f:
    json.dump(result, f, indent=2)
LOADTEST
" || {
    echo '{"status": "ERROR", "error": "Model load validation failed"}' > /tmp/neuron-compile/output/result.json
}

echo "‚úÖ Model validation complete"

# =============================================================================
# Upload Results
# =============================================================================
echo ""
echo "üì§ Uploading results to S3..."
aws s3 cp /tmp/neuron-compile/output/result.json "$OUTPUT_S3_URI/result.json"
if [ -f /tmp/neuron-compile/output/compiled_model.pt ]; then
    aws s3 cp /tmp/neuron-compile/output/compiled_model.pt "$OUTPUT_S3_URI/compiled_model.pt"
fi

# Upload compilation logs if they exist
if [ -f /tmp/neuron-compile/output/log-neuron-cc.txt ]; then
    aws s3 cp /tmp/neuron-compile/output/log-neuron-cc.txt "$OUTPUT_S3_URI/log-neuron-cc.txt"
fi

echo ""
echo "=============================================="
echo "‚úÖ NEURON VALIDATION COMPLETE"
echo "=============================================="
echo ""
echo "üìä Results uploaded to: $OUTPUT_S3_URI"
echo ""
echo "üéØ To use the compiled model:"
echo ""
echo "   Option 1: Run in Docker (Recommended - matches compilation environment)"
echo "   ---------------------------------------------------------------"
echo "   docker run -it --rm -v /tmp/neuron-compile:/app \\"
echo "     {{ container_image }} bash"
echo ""
echo "   Then in Docker:"
echo "   >>> python3"
echo "   >>> import torch"
echo "   >>> model = torch.jit.load('/app/output/compiled_model.pt')"
echo "   >>> print('Model loaded successfully!')"
echo ""
echo "   Option 2: Copy to your own environment"
echo "   ---------------------------------------------------------------"
echo "   Requires: PyTorch 2.9.0 + torch-neuronx {{ neuron_sdk_version }}"
echo "   Model location: /tmp/neuron-compile/output/compiled_model.pt"
echo ""
echo "üìö Compilation Environment:"
echo "   - Docker Image: {{ container_image }}"
echo "   - PyTorch: 2.9.0"
echo "   - Neuron SDK: {{ neuron_sdk_version }}"
echo ""